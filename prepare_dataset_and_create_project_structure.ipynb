{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Datasets and Create the Project Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to preprocess the dataset and create a proper folder structure to store the data. This notebook must be run before running the `Data_Augmentation_Using_Generative_Adversarial_Networks.ipynb` notebook that should be available in the same folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the Cityscapes dataset is downloaded and placed in the directory named **dataset**. The dataset can be downloaded from [here](https://www.cityscapes-dataset.com/). You need to register to access the dataset. The following datasets are required for data augmentation:\n",
    "1. [gtFine_trainvaltest.zip](https://www.cityscapes-dataset.com/file-handling/?packageID=1) (241MB): Fine annotations for training and validation datasets (3475 annotated images) and dummy annotations (ignore regions) for the test set (1525 images).\n",
    "2. [leftImg8bit_trainvaltest.zip](https://www.cityscapes-dataset.com/file-handling/?packageID=3) (11GB): Left 8-bit images - training, validation, and test datasets (5000 images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "assert (platform.python_version_tuple()[:2] >= ('3','7')), \"The notebooks are tested on Python 3.7 and higher. Please updated your Python to evaluate the code\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Notebook server has access to all required resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dataset_folder = Path(\"dataset\")\n",
    "dataset_folder = Path.joinpath(Path.cwd(), dataset_folder)\n",
    "\n",
    "if not dataset_folder.exists():\n",
    "    raise FileNotFoundError(\"Add `{}` folder in the current directory (`{}`)\".format(dataset_folder.name, Path.cwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_zipped_datasets = [\"gtFine_trainvaltest.zip\", \"leftImg8bit_trainvaltest.zip\"]\n",
    "expected_zipped_datasets_path = list()\n",
    "\n",
    "for zipped_dataset in expected_zipped_datasets:\n",
    "    zipped_dataset = Path.joinpath(dataset_folder, zipped_dataset)\n",
    "    expected_zipped_datasets_path.append(zipped_dataset)\n",
    "    if not zipped_dataset.exists():\n",
    "        raise FileNotFoundError(\"Download and place `{}` in the current directory (`{}`)\".format(zipped_dataset.name, Path.cwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "\n",
    "unzipped_datasets_name = [str(dataset_name).replace(\".zip\", \"\") for dataset_name in expected_zipped_datasets]\n",
    "unzipped_datasets_path = [Path.joinpath(dataset_folder, dataset_name) for dataset_name in unzipped_datasets_name]\n",
    "\n",
    "for iterator, (dataset_input_path, dataset_output_path) in enumerate(zip(expected_zipped_datasets_path, unzipped_datasets_path)):\n",
    "    with zf.ZipFile(dataset_input_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dataset_output_path)\n",
    "        \n",
    "    print(f\"Unzipped {(iterator+1)/len(expected_zipped_datasets_path) * 100:.2f}% Dataset.\")\n",
    "        \n",
    "print(\"Unzipped Datasets Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Evaluate Overall Dataset\n",
    "\n",
    "segmentation_map_expr_overall = str(unzipped_datasets_path[0]) + \"\\\\**\\\\*_color.png\"\n",
    "segmentation_map_paths_overall = glob.glob(segmentation_map_expr_overall, recursive=True)\n",
    "segmentation_map_paths_overall = sorted(segmentation_map_paths_overall)\n",
    "\n",
    "photo_expr_overall = str(unzipped_datasets_path[1]) + \"\\\\**\\\\*_leftImg8bit.png\"\n",
    "photo_paths_overall = glob.glob(photo_expr_overall, recursive=True)\n",
    "photo_overall = sorted(photo_paths_overall)\n",
    "\n",
    "print(\"\\nOverall Dataset: \\nFound {} images of segmentation maps.\\nFound {} photos.\".format(len(segmentation_map_paths_overall), len(segmentation_map_paths_overall)))\n",
    "\n",
    "assert (len(segmentation_map_paths_overall) == len(photo_overall)), (\"Dataset Incorrect! Number of semantic segmentation maps do not match the number of photos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Training Dataset\n",
    "\n",
    "segmentation_map_expr_train = str(unzipped_datasets_path[0]) + \"\\\\**\\\\train\\\\**\\\\*_color.png\"\n",
    "segmentation_map_paths_train = glob.glob(segmentation_map_expr_train, recursive=True)\n",
    "segmentation_map_paths_train = sorted(segmentation_map_paths_train)\n",
    "\n",
    "photo_expr_train = str(unzipped_datasets_path[1]) + \"\\\\**\\\\train\\\\**\\\\*_leftImg8bit.png\"\n",
    "photo_paths_train = glob.glob(photo_expr_train, recursive=True)\n",
    "photo_train = sorted(photo_paths_train)\n",
    "\n",
    "print(\"\\nTraining Dataset: \\nFound {} images of segmentation maps.\\nFound {} photos.\".format(len(segmentation_map_paths_train), len(photo_train)))\n",
    "\n",
    "assert (len(segmentation_map_paths_train) == len(photo_train)), (\"Dataset Incorrect! Number of semantic segmentation maps do not match the number of photos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Validation Dataset\n",
    "\n",
    "segmentation_map_expr_val = str(unzipped_datasets_path[0]) + \"\\\\**\\\\val\\\\**\\\\*_color.png\"\n",
    "segmentation_map_paths_val = glob.glob(segmentation_map_expr_val, recursive=True)\n",
    "segmentation_map_paths_val = sorted(segmentation_map_paths_val)\n",
    "\n",
    "photo_expr_val = str(unzipped_datasets_path[1]) + \"\\\\**\\\\val\\\\**\\\\*_leftImg8bit.png\"\n",
    "photo_paths_val = glob.glob(photo_expr_val, recursive=True)\n",
    "photo_val = sorted(photo_paths_val)\n",
    "\n",
    "print(\"\\nValidation Dataset: \\nFound {} images of segmentation maps.\\nFound {} photos.\".format(len(segmentation_map_paths_val), len(photo_val)))\n",
    "\n",
    "assert (len(segmentation_map_paths_val) == len(photo_val)), (\"Dataset Incorrect! Number of semantic segmentation maps do not match the number of photos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Test Dataset\n",
    "\n",
    "segmentation_map_expr_test = str(unzipped_datasets_path[0]) + \"\\\\**\\\\test\\\\**\\\\*_color.png\"\n",
    "segmentation_map_paths_test = glob.glob(segmentation_map_expr_test, recursive=True)\n",
    "segmentation_map_paths_test = sorted(segmentation_map_paths_test)\n",
    "\n",
    "photo_expr_test = str(unzipped_datasets_path[1]) + \"\\\\**\\\\test\\\\**\\\\*_leftImg8bit.png\"\n",
    "photo_paths_test = glob.glob(photo_expr_test, recursive=True)\n",
    "photo_test = sorted(photo_paths_test)\n",
    "\n",
    "print(\"\\nTest Dataset: \\nFound {} images of segmentation maps.\\nFound {} photos.\".format(len(segmentation_map_paths_test), len(photo_test)))\n",
    "\n",
    "assert (len(segmentation_map_paths_test) == len(photo_test)), (\"Dataset Incorrect! Number of semantic segmentation maps do not match the number of photos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Images from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "list_of_segmentation_maps = segmentation_map_paths_overall[-3:]\n",
    "list_of_photos = photo_overall[-3:]\n",
    "\n",
    "f, axarr = plt.subplots(len(list_of_segmentation_maps),2, figsize=(30,20))\n",
    "\n",
    "for iterator, (segmentation_map_path, photo_path) in enumerate(zip(list_of_segmentation_maps, list_of_photos)):\n",
    "    segmentation_map_data = img.imread(segmentation_map_path)\n",
    "    photo_data = img.imread(photo_path)\n",
    "    axarr[iterator, 0].imshow(segmentation_map_data)\n",
    "    axarr[iterator, 1].imshow(photo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = Path.joinpath(dataset_folder, \"training_dataset\")\n",
    "os.makedirs(training_dataset)\n",
    "\n",
    "validatation_dataset = Path.joinpath(dataset_folder, \"validatation_dataset\")\n",
    "os.makedirs(validatation_dataset)\n",
    "\n",
    "test_dataset = Path.joinpath(dataset_folder, \"test_dataset\")\n",
    "os.makedirs(test_dataset)\n",
    "\n",
    "print(\"Project Structure Created Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Cityscape Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate if the images are matching pair\n",
    "def evaluate_matching_pair(segmentation_map_path, photo_path):    \n",
    "    \n",
    "    segmentation_map_identifier = os.path.basename(segmentation_map_path).replace(\"_gtFine_color\", \"\")\n",
    "    photo_identifier = os.path.basename(photo_path).replace(\"_leftImg8bit\", \"\")\n",
    "    \n",
    "    assert (segmentation_map_identifier == photo_identifier), (\"Invalid Image Pair! {} and {} are not same!\".format(segmentation_map_identifier, photo_identifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Function to load resized images\n",
    "def load_resized_images(image_path):    \n",
    "    return Image.open(image_path).convert('RGB').resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Training Dataset\n",
    "\n",
    "for iterator, (segmentation_map_path, photo_path) in enumerate(zip(segmentation_map_paths_train, photo_train)):\n",
    "    \n",
    "    evaluate_matching_pair(segmentation_map_path, photo_path)\n",
    "    segmentation_map = load_resized_images(segmentation_map_path)\n",
    "    photo = load_resized_images(photo_path)\n",
    "    \n",
    "    side_by_side_image = Image.new('RGB', (512, 256))\n",
    "    side_by_side_image.paste(segmentation_map, (256, 0))\n",
    "    side_by_side_image.paste(photo, (0, 0))\n",
    "    \n",
    "    output_path = Path.joinpath(training_dataset, \"{}.jpg\".format(iterator))\n",
    "    side_by_side_image.save(output_path, format='JPEG', subsampling=0, quality=100)\n",
    "    \n",
    "    if(iterator%10 == 0):\n",
    "        print(f\"Processed {(iterator+1)/len(segmentation_map_paths_train) * 100:.2f}% Training Dataset.\")\n",
    "        \n",
    "print(\"Training Data Processed Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Validation Dataset\n",
    "\n",
    "for iterator, (segmentation_map_path, photo_path) in enumerate(zip(segmentation_map_paths_val, photo_val)):\n",
    "    \n",
    "    evaluate_matching_pair(segmentation_map_path, photo_path)\n",
    "    segmentation_map = load_resized_images(segmentation_map_path)\n",
    "    photo = load_resized_images(photo_path)\n",
    "    \n",
    "    side_by_side_image = Image.new('RGB', (512, 256))\n",
    "    side_by_side_image.paste(segmentation_map, (256, 0))\n",
    "    side_by_side_image.paste(photo, (0, 0))\n",
    "    \n",
    "    output_path = Path.joinpath(validatation_dataset, \"{}.jpg\".format(iterator))\n",
    "    side_by_side_image.save(output_path, format='JPEG', subsampling=0, quality=100)\n",
    "    \n",
    "    if(iterator%10 == 0):\n",
    "        print(f\"Processed {(iterator+1)/len(segmentation_map_paths_val) * 100:.2f}% Validation Dataset.\")\n",
    "        \n",
    "print(\"Validation Data Processed Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Test Dataset\n",
    "\n",
    "for iterator, (segmentation_map_path, photo_path) in enumerate(zip(segmentation_map_paths_test, photo_test)):\n",
    "    \n",
    "    evaluate_matching_pair(segmentation_map_path, photo_path)\n",
    "    segmentation_map = load_resized_images(segmentation_map_path)\n",
    "    photo = load_resized_images(photo_path)\n",
    "    \n",
    "    side_by_side_image = Image.new('RGB', (512, 256))\n",
    "    side_by_side_image.paste(segmentation_map, (256, 0))\n",
    "    side_by_side_image.paste(photo, (0, 0))\n",
    "    \n",
    "    output_path = Path.joinpath(test_dataset, \"{}.jpg\".format(iterator))\n",
    "    side_by_side_image.save(output_path, format='JPEG', subsampling=0, quality=100)\n",
    "    \n",
    "    if(iterator%10 == 0):\n",
    "        print(f\"Processed {(iterator+1)/len(segmentation_map_paths_test) * 100:.2f}% Test Dataset.\")\n",
    "        \n",
    "print(\"Test Data Processed Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Training Dataset Images\n",
    "\n",
    "training_dataset_expr = str(training_dataset) + \"\\\\**\\\\*.jpg\"\n",
    "training_dataset_paths = glob.glob(training_dataset_expr, recursive=True)\n",
    "training_dataset_paths = sorted(training_dataset_paths)\n",
    "\n",
    "list_of_training_data = training_dataset_paths[:3]\n",
    "\n",
    "f, axarr = plt.subplots(len(list_of_training_data),1, figsize=(15,20))\n",
    "\n",
    "for iterator, training_data_path in enumerate(list_of_training_data):\n",
    "    training_data = img.imread(training_data_path)\n",
    "    axarr[iterator].imshow(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Validation Dataset Images\n",
    "\n",
    "validation_dataset_expr = str(validatation_dataset) + \"\\\\**\\\\*.jpg\"\n",
    "validation_dataset_paths = glob.glob(validation_dataset_expr, recursive=True)\n",
    "validation_dataset_paths = sorted(validation_dataset_paths)\n",
    "\n",
    "list_of_validation_data = validation_dataset_paths[:3]\n",
    "\n",
    "f, axarr = plt.subplots(len(list_of_validation_data),1, figsize=(15,20))\n",
    "\n",
    "for iterator, validation_data_path in enumerate(list_of_validation_data):\n",
    "    validation_data = img.imread(validation_data_path)\n",
    "    axarr[iterator].imshow(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Test Dataset Images\n",
    "\n",
    "test_dataset_expr = str(test_dataset) + \"\\\\**\\\\*.jpg\"\n",
    "test_dataset_paths = glob.glob(test_dataset_expr, recursive=True)\n",
    "test_dataset_paths = sorted(test_dataset_paths)\n",
    "\n",
    "list_of_test_data = test_dataset_paths[:3]\n",
    "\n",
    "f, axarr = plt.subplots(len(list_of_test_data),1, figsize=(15,20))\n",
    "\n",
    "for iterator, test_data_path in enumerate(list_of_test_data):\n",
    "    test_data = img.imread(test_data_path)\n",
    "    axarr[iterator].imshow(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:**\n",
    "\n",
    "Based on the information from the official documentation of the dataset, it can be confirmed that the semantic segmentation map for the test dataset contains dummy annotations and can be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapping Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!!**\n",
    "\n",
    "You have successfully prepared the dataset required and created the project structure to run this project. You can now run the project by running the `Data_Augmentation_Using_Generative_Adversarial_Networks.ipynb` notebook that should be available in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
